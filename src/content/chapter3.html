<p id="chapter3" class="h2 p-2">Глава 3: Измерение памяти </p>

<hr class="border-2">

<p class="justify-style">Возможно, удивительно говорить об измерениях почти в самом начале книги. Мы еще практически ничего не сказали о управлении памятью в .NET, а уже рассматриваем связанные с этим инструменты. Это хорошо продуманное решение. Во-первых, с помощью описанных здесь инструментов мы часто будем иллюстрировать конкретные концепции, которые будут обсуждаться позже. Во-вторых, хотя мы стремимся сделать эту книгу сбалансированной, она имеет очень практическое значение. При рассмотрении различных тем мы коснемся реальных проблем и примеров. С помощью инструментов, описанных в этой главе, вы сможете увидеть, как эти проблемы можно выявить и диагностировать. Эти инструменты помогут глубже понять реализацию теоретических концепций. Кроме того, они незаменимы для исследования возникающих проблем.</p>

<p class="justify-style">Не зная, какие инструменты использовать, сложно проверить, есть ли в вашем процессе проблемы с памятью. Вы не знаете, как убедиться в том, что высокое потребление ресурсов ЦП или памяти связано с управлением памятью .NET. Вы не знаете, в чем может быть причина нежелательного наблюдаемого поведения. Правда в том, что не существует одного, супер универсального швейцарского армейского ножа. Часто необходимо использовать несколько инструментов, чтобы понять поведение вашего процесса. Чтобы в полной мере комфортно чувствовать себя в теме управления памятью, лучше всего научиться пользоваться каждым из них. Мы опишем здесь широкий спектр инструментов. С одной стороны, есть коммерческие продукты с удобными в использовании пользовательскими интерфейсами, где все просто, поэтому можно быстро получить много ответов. Однако эти инструменты позволяют только то, что было задумано их создателями, с очень ограниченной настройкой. С другой стороны, существуют низкоуровневые инструменты, такие как WinDbg, для действительно глубокого анализа. Знание десятков волшебных команд, которые следует использовать в правильном порядке, позволит вам расследовать сбои или детали выделенного типа. Между этими крайностями есть много других инструментов, которые всегда являются компромиссом между универсальностью и простотой использования. По нашему опыту, таких коммерческих программ высокого уровня почти всегда достаточно. Но это «почти» имеет большое значение. Время от времени вы будете сталкиваться с проблемой, которую невозможно решить только с помощью этих программ. Другими словами, рано или поздно ваши руки испачкаются смазкой из двигателя. А когда вы не найдете нужный инструмент, написать свой собственный может быть не так уж и сложно. Эта книга покажет вам несколько приемов самостоятельного проведения анализа!</p>

<p class="justify-style">Возможно, вас удивит отсутствие инструментов статического анализа кода среди представленных здесь. Почти все инструменты основаны на анализе времени выполнения. Это связано с тем, что управление памятью во многом зависит от контекста выполнения. Например, даже самый неэффективный фрагмент кода не окажет негативного влияния на процесс, если связанные с ним операции будут выполняться только один раз в час. Статический анализ кода может помочь, но он также может создавать шум и заставлять вас излишне концентрироваться на нерелевантных частях кода.</p>

<p class="justify-style">Написание производительного кода может быть более сложным, чем написание функционального или чистого кода. Это связано с тем, что очень трудно предсказать, как на самом деле будет работать данный фрагмент кода или каковы приемлемые накладные расходы для данного приложения. Существуют инструменты, которые показывают нарушение некоторых пороговых значений. Но даже в этом случае, без глубокого понимания предмета, вы не можете быть уверены, будут ли эти пороговые значения применимы к вашему приложению в вашей конкретной среде. Вот почему эта глава важна: она помогает вам преодолеть разрыв между теорией и практикой.</p>

<p class="justify-style">Средства, используемые для измерения поведения программ .NET, радикально различаются в зависимости от операционной системы. Именно поэтому в главе рассматриваются два самых популярных из них – Windows и Linux. Из-за очень низкой популярности использования .NET на macOS инструменты (кроме инструментов CLI) для этой платформы в этой книге не описываются.</p>

<p class="justify-style">Хотя знания для интерпретации результатов работы этих инструментов будут предоставлены несколько позже в книге, мы приглашаем вас опробовать их во время чтения, хотя бы немного. Благодаря этому вы приобретете некоторое знакомство, которое пригодится в следующих главах. Очевидно, что не стесняйтесь пропускать инструменты, с которыми вы уже знакомы.</p>

<p class="justify-style">Обратите также внимание, что эта глава немного страдает от проблемы «курицы и яйца» — невозможно продемонстрировать практическую сторону многих тем, связанных с сборщиком мусора (GC), не используя описанные здесь инструменты, но эти инструменты часто требуют хорошего понимания самих тем, связанных с GC. Тем не менее, мы решили объединить все инструменты в одной главе, чтобы избежать перегрузки всей книги и дать вам единое место, к которому можно вернуться при необходимости. Поэтому не беспокойтесь, если вы сразу не поймете каждую деталь, описанную здесь. Мы ожидаем, что вы будете время от времени возвращаться к этой главе, используя эти инструменты в своей повседневной работе, с полным пониманием, полученным из этой книги.</p>

<hr class="border-2">
<p id="chapter3-1" class="h3 p-2">Начинайте измерять на ранней стадии</p>

<p class="justify-style">Какое самое важное правило в вопросах оптимизации производительности? Будь то эксперты или просто разработчики с некоторым опытом решения подобных проблем, все отвечают одинаково: начинайте измерять как можно раньше. Вероятно, каждый слышал фразу о том, что преждевременная оптимизация является корнем всех зол. Во-первых, не имеет смысла тратить часы или дни на оптимизацию кода, который имеет незначительное влияние на приложение. А еще хуже то, что это обязательно сделает код неоправданно сложным, увеличивая стоимость его поддержки. Хорошим правилом будет противоположный подход — вместо того чтобы заранее сосредотачиваться на оптимизации, начните с измерений, чтобы выяснить, есть ли вообще конкретные потребности в производительности. И поскольку эта книга посвящена управлению памятью в .NET, это приводит нас к следующему общему правилу — Начинайте измерять работу сборщика мусора (GC) как можно раньше — которое мы представим в конце этой главы.</p>

<p class="justify-style">Каждое измерение может сопровождаться большей или меньшей погрешностью. Кроме того, измерение может мешать наблюдаемому процессу. Мы знаем этот принцип из физики, и в информатике всё обстоит точно так же. Поэтому ответ на вопрос «как измерять» может быть либо очень простым (если не углубляться в детали), либо очень сложным (если учитывать точность). Разные инструменты предоставляют разную степень точности, и мы немного об этом поговорим. Однако статистические рассуждения о погрешностях измерений выходят за рамки этой книги. Просто имейте в виду, что определённые неточности могут возникнуть каждый раз, когда вы что-то измеряете.</p>

<p class="justify-style">Тем не менее, учитывая его важность в контексте измерений, мы хотим выделить здесь несколько ключевых концепций и распространённых заблуждений.</p>

<hr class="border-2">
<p id="chapter3-1-1" class="h4 p-2">Накладные расходы и инвазивность</p>

<p class="justify-style">Когда дело доходит до инструментов профилирования, всегда важно помнить о двух наиболее важных концепциях:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Накладные расходы</span>: Очень сложно найти инструмент, который не замедляет приложение или не потребляет больше ресурсов каким-либо образом. В этом случае мы говорим о накладных расходах инструмента, которые обычно выражаются в процентах. Это означает, например, что время отклика веб-приложения может увеличиться на несколько процентов. Или эти проценты могут ухудшить плавность анимаций в desktop-приложении. Некоторые инструменты вызывают практически незаметные накладные расходы всего в несколько процентов или даже менее одного процента. Такие инструменты с минимальными накладными расходами можно использовать даже в производственной среде. С другой стороны, существуют инструменты, которые замедляют ваше приложение на порядки. Обычно они предоставляют большое количество детальной информации. Однако из-за значительных накладных расходов их использование ограничивается средами разработки или рабочими станциями отдельных разработчиков.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Инвазивность</span>: Эта концепция схожа и касается того, насколько инструмент влияет на поведение приложения. Требуется ли перезапуск приложения для использования инструмента? Нужны ли дополнительные разрешения или установленные расширения? В идеале ненавязчивое решение можно включать и выключать во время работы приложения, не оказывая на него никакого влияния. С другой стороны, полностью навязчивое решение потребует перекомпиляции вашего приложения и повторной его деплоизации в заданную среду.</p>
    </li>
</ul>

<hr class="border-2">
<p id="chapter3-1-2" class="h4 p-2">Выборка против трассировки</p>

<p class="justify-style">Еще одной характеристикой профилирующих инструментов является способ сбора диагностической информации. Существует два основных подхода:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Трассировка или инструментирование</span>: В этом подходе диагностические данные собираются во время конкретных, выделенных событий (отсюда и другое название — событийный). Примером может служить сохранение трассируемых данных при открытии или закрытии файла, при щелчке мышью или при начале сборки мусора. Неоспоримым преимуществом этого решения является точность данных, поскольку они поступают в момент возникновения события. Однако, если такие события происходят очень часто или вычисление их содержимого требует больших затрат, это может вызвать значительные накладные расходы. Поэтому этот вид механизма не используется для частых событий, таких как вход в функцию или возврат из нее, если только вы можете позволить себе такие накладные расходы, например, на локальной рабочей станции разработчика.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Выборка</span>: В этом подходе точность жертвуется ради снижения накладных расходов. Идея состоит в том, чтобы собирать диагностические данные периодически (отсюда и другое название — временной). Чем реже вы это делаете, тем меньше будут накладные расходы, но одновременно с этим уменьшится точность измерений. Типичным примером такого подхода является регулярная проверка стеков вызовов функций на всех процессорах, например, каждые 1 мс. Это позволяет статистически определить, какие функции занимают больше всего времени на выполнение. Хотя, конечно, существует вероятность, что вы можете не зафиксировать информацию о функциях, которые всегда выполняются быстрее, чем за 1 мс.</p>
    </li>
</ul>

<hr class="border-2">
<p id="chapter3-1-3" class="h4 p-2">Дерево вызовов</p>

<p class="justify-style">Одной из часто используемых визуализаций поведения потоков приложения является построение дерева вызовов. В таком дереве каждая вершина представляет одну функцию. Подчиненные вершины представляют другие функции, которые были вызваны данной функцией. Каждая функция также сопровождается некоторыми измерениями, чаще всего общим временем выполнения. На практике для каждой функции очень часто используются две связанные метрики:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Эксклюзивная (Exclusive)</span>: Измеряет значение только для этой функции. В случае времени выполнения это будет время, проведенное непосредственно в этой функции (без учета подчиненных функций).</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Инклюзивная (Inclusive)</span>: Измеряет значение для данной функции и сумму значений всех ее потомков. В случае времени выполнения это будет время, проведенное в самой функции, во всех других функциях, вызванных ею, во всех функциях, вызванных ими, и так далее, рекурсивно.</p>
    </li>
</ul>

<p class="justify-style">Кроме того, иногда определяется процент данного показателя относительно всего исследуемого диапазона. Это известно как инклюзивный % и эксклюзивный % измерений. Рассмотрим пример на <a href="#f-3-1">рисунке 3-1</a>, показывающем результаты гипотетического профилировщика.</p>

<p class="justify-style">Вы видите здесь, что 100% времени работы программы было потрачено в функции main — это составило 3 секунды. Функция main просто вызывает все остальные функции, поэтому такое поведение ожидаемо. Однако только 22% этого времени было потрачено непосредственно в самой функции main; остальное время ушло на выполнение других функций, вызванных ею. Например, 78% времени было потрачено на выполнение функции SomeClass.Method1. Затем 66,7% времени работы программы было затрачено на вызов функции SomeClass.HelperMethod. Обходя это дерево вызовов, вы быстро сможете определить, какие компоненты приложения работают медленнее всего.</p>

<p class="justify-style">Обратите также внимание, что такие деревья обычно представляют агрегированные данные. В примере с <a href="#f-3-1">рисунка 3-1</a> агрегируются все упомянутые вызовы методов. Таким образом, метод main был вызван всего один раз, в то время как метод HelperMethod был вызван 2000 раз (что объясняет, почему его агрегированное инклюзивное время так велико). Следовательно, анализ такого дерева включает поиск методов, которые выполняются долго, или методов, которые сами по себе не являются медленными, но вызываются множество раз.</p>

<figure id="f-3-1" class="figure">
    <img src="content/img/3-1.png" class="img-fluid" alt="Рисунок 3-1" max-width="600">
    <figcaption class="figure-caption">Рисунок 3-1. Пример дерева вызовов, показывающего данные о производительности</figcaption>
</figure>

<p class="justify-style">Ту же идею можно использовать для визуализации использования памяти, где каждая вершина представляет собой определенный тип объекта. Типы объектов, на которые ссылается данная вершина, отображаются как ее дочерние элементы. При анализе производительности или потребления памяти вашего приложения вы часто будете использовать такие типы визуализации.</p>

<hr class="border-2">
<p id="chapter3-1-4" class="h4 p-2">Графы объектов</p>

<p class="justify-style">В контексте памяти часто используется граф, представляющий отношения между объектами в памяти, называемый графом объектов или графом ссылок. Пример такого графа можно было видеть на <a href="#f-1-12" onclick="loadContent('chapter1.html', 'f-1-12')">рисунке 1-12</a> в первой главе и он также иллюстрируется на <a href="#f-3-2">рисунке 3-2</a> он показывает набор объектов, ссылающихся друг на друга, с единственным корневым элементом. Визуализация всего графа затруднительна, поскольку он может быть очень большим, поэтому обычно анализируют только его небольшую часть. С их помощью можно отображать как агрегированную информацию (сколько экземпляров данного типа содержат ссылки на другие объекты), так и информацию о конкретном экземпляре.</p>

<figure id="f-3-2" class="figure">
    <img src="content/img/3-2.png" class="img-fluid" alt="Рисунок 3-2" max-width="600">
    <figcaption class="figure-caption">Рисунок 3-2. Пример графа объектов. Дополнительно помечен сохраненный подграф объекта B</figcaption>
</figure>

<p class="justify-style">При работе с графами объектов возникают три важные концепции, которые появляются в различных инструментах, которыми вам представится возможность пользоваться:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Кратчайший путь к корню</span>: Для данного объекта это самый короткий путь ссылок к какому-либо корневому элементу. На <a href="#f-3-2">рисунке 3-2</a> кратчайший путь к корню для объекта H — это путь root-A-H. Также существуют более длинные пути: root-A-C-G-H и root-A-B-G-H. Кратчайший путь к корню может быть важен, так как он чаще всего указывает на главные и наиболее значимые связи между объектами, давая хорошее представление о главной причине, из-за которой объект считается недостижимым (и, следовательно, неподлежащим удалению). Другие пути обычно создаются как побочный эффект других сложных зависимостей. Однако иногда кратчайший путь к корню может быть обманчивым, если он создается вспомогательными ссылками, такими как кэши. Это может быть случай на <a href="#f-3-2">рисунке 3-2</a>, где объект A, вероятно, содержит ссылку на объект H для удобства (например, для кэширования), в то время как фактический "владелец" объекта H находится среди объектов B, C или G.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Подграф зависимостей</span>: Для данного объекта это подграф, который включает сам объект и все объекты, прямо или косвенно на него ссылающиеся. На <a href="#f-3-2">рисунке 3-2</a> подграф зависимостей объекта B включает объект B и объекты D, E, F, G и H.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Подграф удерживаемых объектов</span>: Для данного объекта это подграф, который был бы удален, если бы сам этот объект был удален. Поскольку граф зависимостей может быть сложным, удаление объекта не обязательно означает, что все объекты, на которые он ссылается, также будут удалены. Ссылки на них могут сохраняться другими объектами. Подграф удерживаемых объектов для объекта B на рисунке 3-2 включает объект B и объекты D, E и F.</p>
    </li>
</ul>

<p class="justify-style">Вместе с этими концепциями существуют также различные интерпретации того, как указывается размер объекта в инструментах:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Поверхностный размер (Shallow size)</span>: Сумма поверхностного размера объекта и всех поверхностных размеров объектов, на которые он прямо или косвенно ссылается. Иными словами, это общий размер всех объектов в подграфе зависимостей. Это тоже несложно вычислить, так как нужно просто найти подграф зависимостей объекта и просуммировать все поверхностные размеры включенных объектов.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Удерживаемый размер (Retained size)</span>: Общая сумма всех объектов в графе удержания. Иными словами, удерживаемый размер — это объем памяти, который может быть освобожден после удаления данного объекта. Чем больше объектов разделяется различными ссылками в графе объектов, тем дольше требуется время для его вычисления. Удерживаемый размер меньше общего размера. Это сложно вычислить, так как это требует сложного анализа всего графа объектов.</p>
    </li>
</ul>

<p class="justify-style">Каждый раз, когда используемый вами инструмент говорит о размере объекта, стоит задаться вопросом, какой из упомянутых "размеров" принимается во внимание.</p>

<hr class="border-2">
<p id="chapter3-1-5" class="h4 p-2">Статистика</p>

<p class="justify-style">Каждый раз, когда вы агрегируете измерения различными способами, вы в той или иной степени используете статистические инструменты. Если вы делаете это бессознательно, это может привести к риску ошибочных выводов. Например, самый распространенный метод агрегации данных — это расчет среднего значения, которое должно давать представление о "типичном значении". Однако у среднего значения есть два существенных недостатка: его результаты не указывают на какой-либо конкретный пример (подумайте о том, как в среднестатистической семье 2,43 ребенка), и оно легко скрывает истинную природу распределения данных (что скоро будет продемонстрировано). Такие проблемы, как и другие простые меры, например дисперсия, отлично иллюстрируются так называемым "квартетом Анскомба" (см. <a href="#f-3-3">рисунок 3-3</a>, взятый из Википедии). Иногда совершенно различные наборы данных могут привести к одинаковым статистическим выводам.</p>

<figure id="f-3-3" class="figure">
    <img src="content/img/3-3.png" class="img-fluid" alt="Рисунок 3-3" max-width="600">
    <figcaption class="figure-caption">Рисунок 3-3. Квартет Энскомба – четыре набора данных с одинаковым средним значением и дисперсией данных x и y. Источник: Википедия</figcaption>
</figure>

<p class="justify-style">Причины такой популярности среднего значения заключаются в его интуитивности и возможности легко вычислять его без хранения отдельных выборок. Другие методы агрегации требуют сохранения всех выборок, что может создать значительные накладные расходы для инструмента.</p>

<p class="justify-style">Какие другие методы агрегации стоит использовать? Наиболее распространенные из них включают:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Перцентиль</span>: Значение, ниже которого находится заданный процент выборок. Например, 95-й перцентиль — это значение, ниже которого находятся 95% выборок. Это отличный показатель данных, которые вас интересуют, не учитывая при этом очень аномальные измерения. Мы настоятельно рекомендуем вам измерять перцентили с помощью используемых инструментов. Перцентили часто определяются бизнес-требованиями. Например, вы можете захотеть убедиться, что 90% времени ответа вашего приложения не превышают 1 секунду, а 99% не превышают 4 секунды. Измерение 90-го и 99-го перцентилей времени ответа позволяет вам легко контролировать эти ожидания.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Медиана</span>: Это значение, которое встречается чаще всего в наборе данных. Она может быть полезна для категориальных данных, но не так хорошо подходит для непрерывных данных.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Квартили</span>: Значение, которое делит выборки на верхнюю и нижнюю половины. Обратите внимание, что медиана фактически является 50-м перцентилем. Она лучше отражает типичное значение, так как более устойчива к сильно различающимся выборкам. Кроме того, она указывает на одно из реальных значений, а не на искусственное, рассчитанное.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Гистограмма</span>: Графическое представление распределения выборок. Она показывает, сколько выборок попадает в конкретные диапазоны значений. Это лучший возможный способ измерения, так как он демонстрирует все распределение данных.</p>
    </li>
</ul>

<p class="justify-style">Все эти метрики представлены на <a href="#f-3-4">рисунке 3-4</a>, который показывает гистограмму распределения времени ответа — сколько ответов попадает в каждый временной диапазон (выраженный в миллисекундах). Из гистограммы очевидно, что наиболее распространённое время ответа находится в пределах 110 ± 5 мс, и чем больше время ответа отличается от этого значения, тем реже оно встречается. Более того, можно сказать, что:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style">Среднее время ответа составляет 104,3 мс.</p>
    </li>
    <li>
        <p class="justify-style">10% всех ответов короче 60 мс (10-й перцентиль).</p>
    </li>
    <li>
        <p class="justify-style">Медиана равна 100 мс (50-й перцентиль).</p>
    </li>
    <li>
        <p class="justify-style">90% всех ответов короче 150 мс (90-й перцентиль).</p>
    </li>
</ul>

<figure id="f-3-4" class="figure">
    <img src="content/img/3-4.png" class="img-fluid" alt="Рисунок 3-4" max-width="600">
    <figcaption class="figure-caption">Рисунок 3-4. Пример гистограммы со значениями медианы, 10-го и 90-го процентилей – нормальное распределение данных</figcaption>
</figure>

<p class="justify-style">Распределение, показанное на <a href="#f-3-4">рисунке 3-4</a>, очень похоже на так называемое нормальное распределение, которое часто также называют кривой в форме колокола из-за его характерной формы. Многие измерения будут относиться к этой категории, что делает интерпретацию перцентилей (и даже среднего значения) достаточно логичной.</p>

<p class="justify-style">Однако будьте особенно внимательны к появлению так называемых бимодальных (и многомодальных в общем случае) распределений данных. Интерпретация таких данных только через среднее значение, медиану или перцентили может привести к ошибочным выводам (см. <a href="#f-3-5">рисунок 3-5</a>). В этом примере измеряются два типа ответов (фактически, две различные нормальные кривые), поэтому любая агрегация этих данных будет вводить в заблуждение. Лучше сказать, что существуют две категории ответов с медианами около 40 и 150 мс (и, вероятно, стоит исследовать, почему возникает такое бимодальное время ответа в первую очередь).</p>

<figure id="f-3-5" class="figure">
    <img src="content/img/3-5.png" class="img-fluid" alt="Рисунок 3-5" max-width="600">
    <figcaption class="figure-caption">Рисунок 3-5. Пример гистограммы с отображением значений медианы, 10-го и 90-го процентилей – бимодальное распределение данных</figcaption>
</figure>

<p class="justify-style">К счастью, многомодальное распределение легко обнаружить визуально на гистограмме; именно поэтому так критически важно иметь графическое представление данных при измерении чего-либо (или хотя бы автоматическое указание на обнаружение многомодального распределения).</p>

<p class="justify-style">Чем больше инструмент предлагает различных измерений, помимо среднего значения, тем лучше. К сожалению, подавляющее большинство инструментов всё ещё используют только среднее значение (при этом очень немногие показывают какие-либо гистограммы). Нужно быть крайне осторожным при формулировании выводов. Идеальным решением будет попытаться использовать инструмент, который покажет вам распределение результатов с помощью перцентилей или в виде гистограммы.</p>

<hr class="border-2">
<p id="chapter3-1-6" class="h4 p-2">Латентность против пропускной способности</p>

<p class="justify-style">Два понятия очень важны в контексте любого анализа и оптимизации производительности. К сожалению, их также иногда неправильно понимают и неправильно интерпретируют. Чаще всего вы думаете, что одно вытекает из другого и что они полностью зависят друг от друга. Поэтому стоит дать им несколько слов пояснения. Начнем с их простых определений:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Латентность</span> (latency): Время, необходимое для выполнения заданного действия. Оно измеряется в некоторых единицах времени – днях, часах, миллисекундах и так далее.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Пропускная способность</span> (throughput): Количество действий, выполненных за определенный промежуток времени. Он измеряется в действиях (или в том, что представляет собой отдельный конкретный элемент) в единицу времени — например, в байтах в секунду, итерациях в миллисекунду или книгах в год.</p>
    </li>
</ul>

<p class="justify-style">Простое уравнение, называемое законом Литтла, обозначает взаимосвязь между этими показателями:</p>

<p class="justify-style"><span class="fw-bold fst-italic">occupancy = latency * throughput</span></p>

<p class="justify-style">Где <span class="fw-bold fst-italic">occupancy</span> (занятость) - означает количество действий в течение периода времени, обозначенного задержкой. Важно понимать, что уравнение применимо к стабильной системе, в которой нет неестественной очереди или динамической адаптации к изменению нагрузки (например, во время запуска или выключения системы).</p>

<p class="justify-style">Эти два понятия чаще всего встречаются в контексте компьютерных сетей, но для наших целей мы используем более полезный контекст веб-приложений. Время обработки одного запроса пользователя является латентностью. Количество пользовательских запросов за единицу времени — это пропускная способность. Занятость будет равна количеству запросов, обработанных в системе за рассматриваемый период времени.</p>

<p class="justify-style">Конечно, снижение латентности (например, путем использования более мощного процессора) позволяет приложению обрабатывать больше пользовательских запросов за единицу времени, что также увеличивает пропускную способность. С другой стороны, вы можете повысить пропускную способность просто за счет увеличения количества параллельно обрабатываемых запросов (например, путем использования большего числа ядер процессора) без изменения латентности (см. <a href="#f-3-6">рисунок 3-6</a>). Общее правило информатики заключается в том, что легче увеличить пропускную способность (путем какой-либо параллелизации), чем снизить латентность (например, с помощью более современного оборудования или улучшения алгоритмов).</p>

<figure id="f-3-6" class="figure">
    <img src="content/img/3-6.png" class="img-fluid" alt="Рисунок 3-6" max-width="600">
    <figcaption class="figure-caption">Рисунок 3-6. Соотношение пропускной способности и задержки: (a) при некоторой базовой задержке обрабатывается 5 запросов в X секунд; (b) при уменьшенной задержке было обработано 7 запросов в X секунд; (c) за счет удвоения распараллеливания пропускная способность удваивается до 10 запросов в X секунд без изменения задержки</figcaption>
</figure>

<p class="justify-style">Конечно, бесконечно увеличивать пропускную способность нельзя. И часто, после некоторого порогового значения, дальнейшее увеличение пропускной способности также может увеличить задержку. Дополнительные затраты на синхронизацию могут отрицательно повлиять на задержку и свести на нет выигрыш от увеличения пропускной способности.</p>

<p class="justify-style">Существует также популярный закон Амдала, вытекающий из того факта, что потенциальное ускорение задержки ограничено последовательными (невозможными для распараллеливания) частями программы. Так, например, если 90% части программы может быть распараллелено, то все равно останется 10%, которые будут выполняться последовательно. Следовательно, максимальное потенциальное ускорение в таких случаях ограничивается максимум десятикратным увеличением.</p>

<br>
<div class="card text-bg-info mb-3 bg-opacity-10">
  <div class="card-header"><i class="bi bi-info-square"></i> Примечание</div>
  <div class="card-body">
    <p class="card-text justify-style">Обратите внимание, что он распространяется на все приложение и базовые библиотеки, среду выполнения и другие компоненты, а не только на ваш код. Таким образом, в случае ASP.Net веб-приложения, даже если вся обработка запросов может быть распаралленена, все равно могут присутствовать некоторые последовательные части, такие как управление сессиями, части фреймворка/хостинга и части выполнения сборщика мусора.</p>
  </div>
</div>

<hr class="border-2">
<p id="chapter3-1-7" class="h4 p-2">Дампы памяти, трассировка, отладка в реальном времени</p>

<p class="justify-style">Для того чтобы проанализировать состояние вашего приложения, у вас есть несколько стандартных подходов, которые отличаются по инвазивности:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Мониторинг</span>: Обычно означает неинвазивный мониторинг приложения и использование диагностической информации, которую оно генерирует (с помощью отслеживания или выборки). Иногда он принимает более инвазивную форму (например, перезапуск приложения), но его можно использовать в производстве, если накладные расходы достаточно низки.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Дамп ядра (дамп памяти)</span>: Означает сохранение состояния памяти процесса в определенный момент. В большинстве случаев состояние всей памяти сохраняется в файле. Затем этот файл можно проанализировать с помощью различных инструментов, даже на другой машине. Поскольку это копия памяти, дамп памяти может занимать десятки гигабайт, но при наличии соответствующих навыков он может предоставить очень подробную информацию о состоянии вашего приложения. С другой стороны, это всего лишь снимок процесса в определенный момент, и без контекста изменения во времени иногда бывает трудно прийти к конкретным выводам, например, при поиске утечек памяти. Поэтому можно захватить два или более дампа памяти и сравнить их друг с другом, чтобы точно определить изменения. Захват дампа памяти может быть очень инвазивным. Чаще всего он заставляет процесс приостанавливаться на некоторое время, от пары секунд до нескольких минут, если целевое приложение использует много памяти. Важное применение дампов памяти — их автоматическое создание после сбоя приложения, что позволяет позднее исследовать его причину (так называемый посмертный анализ) — следовательно, вы можете также обнаружить имя аварийного дампа как особый случай дампа памяти. На практике понятия аварийного дампа и дампа памяти используются взаимозаменяемо в инструментах, с которыми вы столкнетесь.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Отладка в реальном времени</span>: Наиболее инвазивный подход — подключить отладчик к процессу и пошагово проанализировать выполнение приложения. Это наиболее распространенный подход на машине разработчика. К сожалению, для защищенных или чувствительных производственных сред вам придется полагаться на предыдущие два подхода, что довольно необычно в случае расследования проблем с памятью.</p>
    </li>
</ul>

<hr class="border-2">
<p id="chapter3-2" class="h3 p-2">Окружения Windows и Linux</p>

<p class="justify-style">CLR был представлен общественности в 2000 году вместе с .NET Framework, работающим только на Windows. Одной из главных целей .NET Core было выполнение на большем количестве операционных систем (Linux и OSX). Соответствующий инструментарий для мониторинга и анализа производительности, включая распределение памяти на Linux, должен был ждать версии 3.0, чтобы стать доступным. В этом разделе описывается бесплатный инструментарий, используемый в остальной части книги.</p>

<br>
<div class="card text-bg-info mb-3 bg-opacity-10">
  <div class="card-header"><i class="bi bi-info-square"></i> Примечание</div>
  <div class="card-body">
    <p class="card-text justify-style">Обратитесь к бесплатной электронной книге по адресу <a href="https://prodotnetmemory.com/assets/files/Chapter03_Pre30LinuxTooling.pdf" target="_blank">https://prodotnetmemory.com/assets/files/Chapter03_Pre30LinuxTooling.pdf</a> в которой описан инструментарий Linux для версий .NET Core до 3.0.</p>
  </div>
</div>

<hr class="border-2">
<p id="chapter3-2-1" class="h4 p-2">Обзор</p>

<p class="justify-style">Инфраструктура мониторинга и трассировки Windows очень зрелая, в том числе в контексте среды выполнения .NET. Доступны два основных компонента: система на основе метрик для предоставления временных рядов измерений и механизм на основе событий, называемый <span class="fw-bold fst-italic">Event Tracing for Windows (ETW)</span>. Этих двух достаточно, чтобы покрыть почти все потребности в мониторинге и диагностике. Также есть механизм Windows Management Instrumentation, но он вообще не используется для наших целей (поскольку он больше предназначен, как следует из его названия, для управления и администрирования).</p>

<p class="justify-style">При разработке .NET выбор в области диагностического механизма был очевидным. Как зрелый .NET Framework, так и его многоплатформенный аналог .NET Core поддерживают ETW (Event Tracing for Windows) как диагностическую платформу на Windows. .NET Core также поддерживает EventPipes — кроссплатформенный канал передачи диагностических событий, который использует именованные каналы (Named Pipes) на Windows и сокеты Unix Domain Sockets для Linux и macOS. Ситуация сложнее с мониторингом на основе метрик. .NET Framework работает только на Windows, поэтому метрики публикуются как счетчики производительности Windows. Для .NET Core, начиная с версии 3.0, счетчики публикуются через EventPipes. Прежде чем рассмотреть инструменты, основанные на счетчиках и событиях, будет интересно взглянуть на инструмент, работающий только на Windows, который обеспечивает уникальное представление адресного пространства процесса.</p>

<hr class="border-2">
<p id="chapter3-2-2" class="h4 p-2">VMMap</p>

<p class="justify-style">Этот отличный инструмент, являющийся частью набора утилит Microsoft Sysinternals, позволяет анализировать адресное пространство процесса с точки зрения операционной системы. В последующих главах мы будем использовать его для того, чтобы увидеть, как приложение .NET использует память, исходя из описанной во второй главе структуры (страницы, которые могут быть выделены или зарезервированы для различных целей).</p>

<p class="justify-style">Это автономный инструмент, который не требует установки и может быть скачан с сайта <a href="https://learn.microsoft.com/en-us/sysinternals/downloads/vmmap">(https://learn.microsoft.com/en-us/sysinternals/downloads/vmmap)</a>. После распаковки и запуска вы можете выбрать процесс, чтобы сразу увидеть анализ его использования памяти (см. <a href="#f-3-7">рисунок 3-7</a>). VMMap обнаруживает страницы, выделенные для стека или загруженных бинарных файлов. Для приложений .NET вы также можете увидеть страницы, выделенные для Управляемой Кучи (Managed Heap).</p>

<figure id="f-3-7" class="figure">
    <img src="content/img/3-7.png" class="img-fluid" alt="Рисунок 3-7" max-width="600">
    <figcaption class="figure-caption">Рисунок 3-7. Образец просмотра простого приложения .NET Framework (например, управляемые кучи были 
правильно обнаружен)</figcaption>
</figure>

<hr class="border-2">
<p id="chapter3-2-3" class="h4 p-2">Счетчики производительности .NET Framework</p>

<p class="justify-style">Механизм так называемых счетчиков производительности (Performance Counters) является наиболее распространенным инструментом для мониторинга практически всех аспектов Windows. Это очень легковесный механизм, который можно описать одной фразой: процессы могут использовать его для обмена диагностическими данными в форме временных рядов метрик. Его огромное преимущество заключается в том, что это полностью ненавязчивый механизм, который не создает заметных накладных расходов. Недостатком является точность — диспетчер производительности получает значения каждую секунду, что может быть недостаточно для ваших конкретных целей. Кроме того, некоторые поставщики не обновляют значения регулярно; например, среда выполнения .NET изменяет счетчики производительности, связанные с сборкой мусора (GC), только после каждой сборки мусора.</p>

<p class="justify-style">Метрики группируются в различные категории. Общая архитектура счетчиков производительности показана на <a href="#f-3-8">рисунке 3-8</a>.</p>

<figure id="f-3-8" class="figure">
    <img src="content/img/3-8.png" class="img-fluid" alt="Рисунок 3-8" max-width="600">
    <figcaption class="figure-caption">Рисунок 3-8. Архитектура счетчика производительности</figcaption>
</figure>

<p class="justify-style">В общем случае несколько процессов могут решить публиковать данные под определенными счетчиками производительности. У каждого счетчика производительности есть несколько важных атрибутов:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Категория</span>: Определяет общий Scope (область действия) счетчика.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Имя</span>: Однозначно идентифицирует счетчик в рамках данной категории.</p>
    </li>
    <li>
        <p class="justify-style"><span class="fw-bold fst-italic">Имя экземпляра</span>: В системе может быть несколько экземпляров одного и того же счетчика. В большинстве случаев имя экземпляра — это имя процесса.</p>
    </li>
</ul>

<p class="justify-style">Сочетание, которое однозначно идентифицирует счетчик производительности, записывается как "\<Категория>(<Экземпляр>)\<Имя>". Например, счетчик, указывающий на использование CPU процессом notepad (notepad.exe), будет обозначен как "\Process(notepad)\% Processor Time". В случае нескольких экземпляров одного и того же процесса появляется знак #, за которым следует номер экземпляра. Например, если MyApp.exe запущен дважды, будут указаны "MyApp" и "MyApp#1" (подробнее об этом позже).</p>

<p class="justify-style">Какие образцы данных можно получить таким образом? Мы упомянем лишь некоторые из них, чтобы показать богатство предоставленной информации:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style">Как использование CPU распределяется между ядром системы и программами (Processor/% Privileged Time, Processor/% User Time)</p>
    </li>
    <li>
        <p class="justify-style">В какой степени отдельные процессы потребляют ресурсы CPU (Process/% Processor Time)</p>
    </li>
    <li>
        <p class="justify-style">В какой степени и как отдельные процессы используют память (Process/Working Set, Process/Working Set - Private, Process/Private Bytes)</p>
    </li>
    <li>
        <p class="justify-style">Как используется жесткий диск (Process/IO Read Bytes/sec, Process/IO Write Bytes/sec, Process/Page Faults/sec)</p>
    </li>
    <li>
        <p class="justify-style">Сколько операций записи/чтения на диск находится в очереди (PhysicalDisk/Current Disk Queue Length)</p>
    </li>
    <li>
        <p class="justify-style">Сколько исключений генерирует приложение .NET (.NET CLR Exceptions/# of Exceps Thrown/sec)</p>
    </li>
</ul>

<br>
<div class="card text-bg-info mb-3 bg-opacity-10">
  <div class="card-header"><i class="bi bi-info-square"></i> Примечание</div>
  <div class="card-body">
    <p class="card-text justify-style">Счетчики производительности в категориях «.NET» доступны только для .NET Framework. Их эквивалент для .NET Core описан в следующем разделе.</p>
  </div>
</div>

<p class="justify-style">Конечно, вас в первую очередь интересует категория .NET CLR Memory, где можно найти следующие счетчики (орфография и регистры символов сохранены без изменений):</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style"># Bytes in all Heaps</p>
    </li>
    <li>
        <p class="justify-style"># GC Handles</p>
    </li>
    <li>
        <p class="justify-style"># Gen 0 Collections, # Gen 1 Collections, # Gen 2 Collections</p>
    </li>
    <li>
        <p class="justify-style"># Induced GC</p>
    </li>
    <li>
        <p class="justify-style"># of Pinned Objects</p>
    </li>
    <li>
        <p class="justify-style"># of Sink Blocks in use</p>
    </li>
    <li>
        <p class="justify-style"># Total committed Bytes, # Total reserved Bytes</p>
    </li>
    <li>
        <p class="justify-style">% Time in GC</p>
    </li>
    <li>
        <p class="justify-style">Allocated Bytes/sec</p>
    </li>
    <li>
        <p class="justify-style">Finalization Survivors</p>
    </li>
    <li>
        <p class="justify-style">Gen 0 heap size, Gen 1 heap size, Gen 2 heap size, Large Object Heap Size</p>
    </li>
    <li>
        <p class="justify-style">Gen 0 Promoted Bytes/Sec, Gen 1 Promoted Bytes/Sec</p>
    </li>
    <li>
        <p class="justify-style">Process ID</p>
    </li>
    <li>
        <p class="justify-style">Promoted Finalization-Memory from Gen 0</p>
    </li>
    <li>
        <p class="justify-style">Promoted Memory from Gen 0, Promoted Memory from Gen 1</p>
    </li>
</ul>

<br>
<div class="card text-bg-info mb-3 bg-opacity-10">
  <div class="card-header"><i class="bi bi-info-square"></i> Примечание</div>
  <div class="card-body">
    <p class="card-text justify-style">Названия этих счетчиков производительности (как и других в категориях .NET CLR) переводятся на активный язык операционной системы, поэтому на вашем компьютере или сервере могут быть указаны другие названия и категории. Это может быть довольно раздражающим, поскольку во многих переводах эти названия звучат немного странно. Это одна из многих причин, по которым мы рекомендовали бы вам использовать английский язык как основной язык Windows.</p>
  </div>
</div>

<p class="justify-style">Если тема сборки мусора (Garbage Collection) вам хотя бы немного знакома, вы, вероятно, уже догадались о значении большинства из упомянутых выше счетчиков. Вы будете встречать их на протяжении всей остальной части книги. Уже сейчас можно сказать, что это полный набор данных, позволяющий глубоко понять состояние вашего приложения.</p>

<p class="justify-style">Расчет счетчиков синхронизирован с жизненным циклом сборки мусора. В частности, большинство измерений производится в начале или в конце процесса GC. В этом смысле счетчики производительности могут предоставлять очень ценную и точную информацию. Однако есть несколько важных замечаний, которые стоит упомянуть в этом контексте:</p>

<ul class="bullet-list ms-1">
    <li>
        <p class="justify-style">Чтение значений счетчиков производительности полностью зависит от частоты, с которой используемый вами инструмент выполняет их выборку. Если выборка происходит достаточно часто (например, каждую секунду), данные будут полностью точными. Однако если выборка редкая, результаты могут быть ошибочными и вводить в заблуждение. Например, если не повезет и полная сборка мусора (тот, который потребляет больше всего ресурсов) будет происходить непосредственно перед каждым вашим измерением, вы получите ложное представление о том, сколько времени тратится на GC (% Time in GC). Другими словами, при анализе счетчиков производительности следует внимательно следить за способом выборки данных.</p>
    </li>
    <li>
        <p class="justify-style">Данные счетчиков производительности обновляются только при возникновении определенных событий (в основном начала и окончания сборки мусора), после чего их значения остаются неизменными. Это может привести к неверным показаниям. Предположим, например, что в вашем процессе недавно произошла полная сборка мусора, во время которой % Time in GC составил 50%. С этого момента счетчик % Time in GC будет показывать высокое значение 50%, даже если наблюдаемый процесс больше не выполняет никакой работы. Пока не начнется новая сборка мусора, эти значения не будут обновлены. Другими словами, при наблюдении за счетчиками следует уделять больше внимания изменениям, а не текущим значениям. Наблюдаемое значение — это просто последнее измеренное значение.</p>
    </li>
</ul>

<p class="justify-style">Microsoft с версии .NET Framework 4.0 предпочитает использование событий ETW (описано в следующем разделе) для передачи значимой полезной нагрузки вместо счетчиков производительности. Однако использование инструментов счетчиков производительности намного проще, чем любых инструментов, связанных с ETW. Мы подробно рассмотрим различия между измерениями счетчиков производительности и ETW в пятой главе.</p>

<p class="justify-style">Множество инструментов мониторинга используют счетчики производительности, поскольку это очень легковесный и эффективный способ получения большого объема информации. Однако одним из самых простых и часто используемых инструментов является встроенный Windows Performance Monitor. Запустить его можно с помощью команды <span class="fw-bold fst-italic">perfmon.exe</span> или через поиск в меню "Пуск".</p>

<p class="justify-style">Затем выберите пункт <span class="fw-bold fst-italic">Performance ➤ Monitoring Tools ➤ Performance Monitor</span> в левом меню. В появившемся графике, в контекстном меню выберите опцию <span class="fw-bold fst-italic">Add Counters...</span> (см. <a href="#f-3-9">рисунок 3-9</a>).</p>

<figure id="f-3-9" class="figure">
    <img src="content/img/3-9.png" class="img-fluid" alt="Рисунок 3-9" max-width="600">
    <figcaption class="figure-caption">Рисунок 3-9. Монитор производительности – общий вид с опцией контекста «Добавить счетчики»</figcaption>
</figure>

<p class="justify-style">Используйте диалоговое окно для выбора интересующей категории (в нашем случае это память .NET CLR), а также конкретных счетчиков и экземпляров (см. <a href="#f-3-10">рисунок 3-10</a>).</p>

<figure id="f-3-10" class="figure">
    <img src="content/img/3-10.png" class="img-fluid" alt="Рисунок 3-10" max-width="600">
    <figcaption class="figure-caption">Рисунок 3-10. Монитор производительности – диалоговое окно «Добавить счетчики»</figcaption>
</figure>

<p class="justify-style">Текст ...</p>

<p class="justify-style">Текст ...</p>

<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-4" class="h4 p-2">Счетчики .NET Core</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-5" class="h4 p-2">Трассировка событий для Windows</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-6" class="h4 p-2">PerfView</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-7" class="h4 p-2">Инструмент dotnet-trace CLI</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-8" class="h4 p-2">Инструмент dotnet-gcmon CLI</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-9" class="h4 p-2">ProcDump, dotnet-dump</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-10" class="h4 p-2">dotnet-gcdump CLI инструмент</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-11" class="h4 p-2">WinDbg</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-12" class="h4 p-2">dotnet-dump для анализа</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-13" class="h4 p-2">Дизассемблеры и декомпиляторы</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-14" class="h4 p-2">BenchmarkDotNet</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-15" class="h4 p-2">Инструменты от авторов</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-2-16" class="h4 p-2">Коммерческие инструменты</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-3" class="h3 p-2">Резюме</p>
<p class="justify-style">Текст ...</p>

<hr class="border-2">
<p id="chapter3-3-1" class="h4 p-2">Правило 5 — Раннее измерение работы сборщика мусора (GC)</p>
<p class="justify-style">Текст ...</p>



<!--
Глава 3: Измерение памяти  
    Начинайте измерять на ранней стадии  
        Накладные расходы и инвазивность  
        Выборка против трассировки  
        Дерево вызовов  
        Графы объектов  
        Статистика  
        Латентность против пропускной способности  
        Дампы памяти, трассировка, отладка в реальном времени  
    Окружения Windows и Linux  
        Обзор  
        VMMap  
        Счетчики производительности .NET Framework  
        Счетчики .NET Core  
        Трассировка событий для Windows  
        PerfView  
        Инструмент dotnet-trace CLI  
        Инструмент dotnet-gcmon CLI  
        ProcDump, dotnet-dump  
        dotnet-gcdump CLI инструмент  
        WinDbg  
        dotnet-dump для анализа  
        Дизассемблеры и декомпиляторы  
        BenchmarkDotNet  
        Инструменты от авторов  
        Коммерческие инструменты  
    Резюме  
      Правило 5 — Раннее измерение работы сборщика мусора (GC)
-->