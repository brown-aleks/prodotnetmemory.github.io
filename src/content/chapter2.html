<h2 id="chapter2" class="h2 p-2">Глава 2: Низкоуровневое управление памятью</h2>

<hr class="border-2">

<p class="justify-style">В предыдущей главе вы узнали теоретические основы управления памятью. Теперь вы можете сразу перейти к деталям автоматического управления памятью, как работает сборщик мусора и где могут возникать утечки памяти. Но если вы действительно хотите «освоить» эту тему, стоит потратить еще немного времени на низкоуровневые аспекты управления памятью. Это позволит вам лучше понять различные проектные решения, которые были приняты создателями сборщика мусора в .NET (а также других управляемых сред выполнения). Создатели таких механизмов не живут в вакууме и должны адаптироваться к ограничениям и механизмам, которые управляют компьютерным оборудованием и операционными системами.</p>

<p class="justify-style">Вы узнаете о этих механизмах и ограничениях в этой главе. Честно говоря, не так просто представить такие темы в не перегружающей форме. К сожалению, управление памятью в .NET было бы неполным без углубления в эти детали.</p>

<p class="justify-style">Хотя оператор «new» достаточен для большинства сценариев управления памятью в .NET, более глубокое понимание основных процессов и механизмов может оказаться полезным. Оборудование, операционная система и компилятор влияют на то, как это работает и как был написан .NET, хотя это не всегда очевидно. Эти знания очень согласуются с духом Механической Симпатии, представленной в предыдущей главе. Мы надеемся, что вам также будет просто интересно узнать некоторые из упомянутых здесь мелких фактов.</p>

<p class="justify-style">Еще раз, если вы торопитесь или просто хотите перейти к более практическим внутренним аспектам .NET и примерам, не стесняйтесь просмотреть эту главу и вернуться к ней в более свободное время, надеемся.</p>

<hr class="border-2">
<p id="chapter2-1" class="h3 p-2">Аппаратное обеспечение</p>

<p class="justify-style"> Как работает современный компьютер? Вы, вероятно, уже имеете базовое представление о предмете: компьютер состоит из процессора, который является основной вычислительной единицей – он выполняет программы. У него есть доступ к оперативной памяти (которая быстрая) и жестким дискам (которые медленные). Также есть видеокарта, которая очень важна для геймеров (и различных видов графических дизайнеров), которая отвечает за создание изображения, отображаемого на мониторе. Такой обзор с высоты птичьего полета недостаточен для наших целей. Давайте углубимся в тему. Для целей ваших размышлений давайте введем архитектуру современного компьютера, как на диаграмме на <a href="#f-2-1">Рисунке 2-1</a>.</p>

<br>
<div class="card text-bg-info mb-3 bg-opacity-10">
  <div class="card-header"><i class="bi bi-info-square"></i> Примечание</div>
  <div class="card-body">
    <p class="card-text justify-style">Современный рынок персональных компьютеров доминируют ПК и Маки. Смоделированная схема архитектуры общего компьютера основана на них. При необходимости будут введены некоторые возможные нюансы, такие как те, которые касаются процессоров ARM или более сложных серверных машин.</p>
  </div>
</div>

<p class="justify-style">Основные компоненты типичной архитектуры компьютера можно перечислить как</p>

<ul class="bullet-list ms-1">
  <li>
    <p class="justify-style"><span class="fw-bold fst-italic">Процессор</span> (CPU, центральный процессор): Основной блок, отвечающий за выполнение инструкций, как описано в Главе 1. Здесь находятся такие компоненты, как арифметико-логические устройства (ALU), устройства с плавающей запятой (FPU), регистры и конвейеры выполнения инструкций, которые делят инструкции на набор более мелких операций и выполняют их, если возможно, параллельно.</p>
    </li>
    <li>
    <p class="justify-style"><span class="fw-bold fst-italic">Шина передней панели</span> (FSB): Шина данных, соединяющая процессор с северным мостом.</p>
    </li>
    <li>
    <p class="justify-style"><span class="fw-bold fst-italic">Северный мост</span>: Блок, содержащий в основном контроллер памяти, отвечающий за управление связью между памятью и процессором.</p>
    </li>
    <li>
    <p class="justify-style"><span class="fw-bold fst-italic">ОЗУ</span> (оперативная память): Основная память компьютера. Она хранит данные и код программ до тех пор, пока питание включено – поэтому ее также называют динамической оперативной памятью (DRAM) или энергозависимой памятью.</p>
    </li>
    <li>
    <p class="justify-style"><span class="fw-bold fst-italic">Шина памяти</span>: Шина данных, соединяющая ОЗУ с северным мостом.</p>
    </li>
    <li>
    <p class="justify-style"><span class="fw-bold fst-italic">Южный мост</span>: Чип, который обрабатывает все функции ввода-вывода, такие как USB, аудио, последовательный порт, системный BIOS, шина ISA, контроллер прерываний и каналы IDE – контроллеры массового хранения, такие как PATA и/или SATA.</p>
    </li>
    <li>
    <p class="justify-style"><span class="fw-bold fst-italic">Ввод-вывод хранения</span>: Энергонезависимая память, которая хранит данные, включая популярные HDD или SSD диски.</p>
  </li>
</ul>

<figure id="f-2-1" class="figure">
  <img src="content/img/2-1.png" class="img-fluid" alt="Рисунок 2-1" max-width="600">
  <figcaption class="figure-caption">Рисунок 2-1. Архитектура компьютера – ЦПУ, ОЗУ, северный мост, южный мост и другие. Ширина шины иллюстрирует пропорцию объема передаваемых данных (очень приблизительно)</figcaption>
</figure>

<p class="justify-style">Стоит упомянуть, что ранее процессор, северный мост и южный мост были отдельными чипами, но теперь они тесно интегрированы. Начиная с микроархитектур Intel Nehalem и AMD Zen, северный мост включен в кристалл процессора (который в таком случае часто называют <span class="fw-bold fst-italic">uncore</span> или <span class="fw-bold fst-italic">System Agent</span>). Эта эволюция архитектуры показана на <a href="#f-2-2">Рисунке 2-2</a>.</p>

<figure id="f-2-2" class="figure">
  <img src="content/img/2-2.png" class="img-fluid" alt="Рисунок 2-2" max-width="600">
  <figcaption class="figure-caption">Рисунок 2-2. Современное оборудование – процессор с северным мостом внутри, ОЗУ, южный мост (переименованный в Platform Controller Hub в случае терминологии Intel) и другие. Ширина шины иллюстрирует пропорцию объема передаваемых данных (очень приблизительно)</figcaption>
</figure>

<p class="justify-style">Такая интеграция помогает, потому что контроллер памяти (внутри северного моста) расположен ближе к исполнительным блокам процессора, уменьшая задержки за счет меньших физических расстояний и улучшенного взаимодействия. Но на рынке все еще есть процессоры (наиболее популярные из которых – семейство AMD FX), у которых процессор, северный мост и южный мост разделены.</p>

<p class="justify-style">Основная проблема любого управления памятью заключается в несоответствии производительности современных процессоров по отношению к подсистемам памяти и массового хранения. Процессор намного быстрее памяти, поэтому каждый доступ к памяти вызывает нежелательные задержки. Когда процессору приходится ждать доступа к памяти (чтение или запись), это называется остановкой. Остановки негативно влияют на использование процессора, так как приводят к потере циклов процессора на ожидание, а не на выполнение задач.</p>

<p class="justify-style">Типичный современный процессор работает на частоте 3 ГГц или выше. Между тем, память работает с внутренними тактовыми частотами другого порядка величины, всего 200–400 МГц. Было бы слишком дорого создавать микросхемы ОЗУ, работающие на частоте процессоров. Это связано с тем, как устроены современные ОЗУ – зарядка и разрядка внутренних конденсаторов занимает время и его очень трудно уменьшить.</p>

<p class="justify-style">Вас может удивить, что память работает с такими низкими частотами. На самом деле, в компьютерных магазинах модули памяти рекламируются с частотами, такими как 3200 или 4800 МГц, которые гораздо ближе к скорости процессора. Откуда берутся такие цифры? Как вы увидите, такие спецификации – это только часть более сложной истины.</p>

<p class="justify-style">Модули памяти состоят из <span class="fw-bold fst-italic">внутренних ячеек памяти</span> (хранящих данные) и дополнительных буферов, которые помогают преодолеть их низкие внутренние тактовые частоты. Используются некоторые дополнительные приемы (см. <a href="#f-2-3">Рисунок 2-3</a>). Большинство из них основаны на умножении чтения данных:</p>

<ul class="bullet-list ms-1">
  <li>
    <p class="justify-style">Отправка данных из внутренней ячейки памяти дважды в течение одного тактового цикла. Для точности, это как на спаде, так и на подъеме сигнала. Отсюда и название самой популярной памяти различных поколений – <span class="fw-bold fst-italic">Double Data Rate</span> (DDR). Этот метод также называют <span class="fw-bold fst-italic">двойной накачкой</span>.</p>
    </li>
    <li>
    <p class="justify-style">Использование внутренней буферизации для выполнения нескольких чтений одновременно («режим burst») в одном тактовом цикле памяти. Это умножает количество прочитанных данных при той же внутренней частоте. Интерфейс памяти DDR2 удваивает внешнюю тактовую частоту, в то время как DDR3 и DDR4 увеличивают ее в четыре раза. DDR5 удваивает ее еще раз.</p>
    </li>
</ul>

<p class="justify-style">Эти методы в настоящее время используются в модулях DDR в отличие от гораздо более простых модулей SDRAM (синхронный DRAM), использовавшихся в прошлом. В конечном итоге, в случае современных типичных DDR5, кратность «burst» модуля памяти составляет 16, поскольку он сочетает технику двойной накачки с восемью чтениями одновременно.</p>

<figure id="f-2-3" class="figure">
  <img src="content/img/2-3.png" class="img-fluid" alt="Рисунок 2-3" max-width="600">
  <figcaption class="figure-caption">Рисунок 2-3. Внутреннее устройство SDRAM, DDR, DDR2, DDR3, DDR4 и DDR5. Пример модулей памяти с внутренней частотой 300 МГц. MT/s означает «Мега передача в секунду». Обратите внимание, что это не строгая, а скорее иллюстративная диаграмма, показывающая соотношения между внутренними частотами и результирующими MT/s</figcaption>
</figure>

<p class="justify-style">Для иллюстрации давайте рассмотрим типичный чип памяти DDR4, например, 16 ГБ 2400 МГц (описанный в спецификациях как DDR4-2400, PC4-19200). В этих случаях внутренняя тактовая частота массива DRAM составляет 300 МГц. Тактовая частота шины памяти увеличивается в четыре раза до 1200 МГц благодаря внутреннему буферу ввода-вывода. Кроме того, происходит две передачи за каждый тактовый цикл (оба склона сигнала), что приводит к скорости передачи данных 2400 MT/s (мега передача в секунду). Отсюда и берется спецификация 2400 МГц. Проще говоря, из-за природы двойной накачки в памяти DDR, скорость обычно указывается как двойная частота тактовой шины ввода-вывода, которая сама по себе является умножением внутренней тактовой частоты памяти. Указание этого значения в МГц – это просто маркетинговое упрощение. Вторая подпись – PC4-19200 – обладает максимальной теоретической производительностью такой памяти – это 2400 МТ/с, умноженные на 8 байт (передается одно слово длиной 64 бита), что дает результат 19200 МБ/с.</p>

<p class="justify-style">Давайте рассмотрим настольный ПК Конрада в контексте всей архитектуры. Он оснащен процессором Intel Core i7-4770K (поколение Haswell), работающим на частоте 3,5 ГГц. Частота шины передней панели составляет всего 100 МГц. Используемая память DDR3-1600 (PC3-12800) имеет внутреннюю тактовую частоту памяти 200 МГц, и благодаря механизму DDR3 тактовая частота шины ввода-вывода составляет 800 МГц. Это показано на <a href="#f-2-4">Рисунке 2-4</a>. Это подтверждается использованием инструментов аппаратной диагностики, таких как CPU-Z (см. <a href="#f-2-5">Рисунок 2-5</a>).</p>

<p class="justify-style">Модули памяти постоянно улучшаются. Например, для DDR5 основным драйвером изменений было улучшение пропускной способности памяти. Вот почему была введена удвоенная длина burst, наряду с другими аналогичными изменениями, такими как удвоение количества «банков» и «групп банков» или введение двух независимых каналов вместо одного. Однако объяснение этих техник потребовало бы объяснения низкоуровневой работы модулей памяти, что выходит за рамки этой книги.</p>

<p class="justify-style">Если вам это интересно, вы можете начать с постера RAM Anatomy, доступного на сайте <a href="https://prodotnetmemory.com/">https://prodotnetmemory.com/</a>.</p>

<figure id="f-2-4" class="figure">
  <img src="content/img/2-4.png" class="img-fluid" alt="Рисунок 2-4" max-width="600">
  <figcaption class="figure-caption">Рисунок 2-4. Современная аппаратная архитектура с дискретной тактовой частотой (Intel Core i7-4770K и DDR3-1600)</figcaption>
</figure>

<figure id="f-2-5" class="figure">
  <img src="content/img/2-5.png" class="img-fluid" alt="Рисунок 2-5" max-width="600">
  <figcaption class="figure-caption">Рисунок 2-5. Скриншот CPU-Z – вкладка «Память», на которой показаны частоты северного моста (NB) и DRAM, а также соотношение частот FSB:DRAM (которое, к сожалению, неверно в данной версии инструмента и должно быть 1:8)</figcaption>
</figure>

<p class="justify-style">Несмотря на все описанные здесь улучшения памяти DDR, процессоры все еще намного быстрее памяти, которую они используют. Чтобы преодолеть эту проблему, применяется аналогичный подход на разных уровнях – приближение части данных к компоненту с более производительными (и более дорогими) блоками памяти. Такой подход называется кэшированием.</p>

<p class="justify-style">Для массовой памяти, такой как HDD, данные обычно кэшируются в ОЗУ – или в более быстрой, но меньшей по размеру выделенной памяти, такой как небольшой SSD внутри гибридных HDD-дисков, предназначенных для наиболее часто используемых данных. Для ОЗУ данные кэшируются внутри кэша процессора, как вы скоро увидите.</p>

<p class="justify-style">Конечно, существуют более общие оптимизации ОЗУ, включая лучшее аппаратное проектирование, лучшие контроллеры памяти и оптимизацию DMA (Direct Memory Access - прямой доступ к памяти) для устройств. Однако DMA не рассматривается в этой книге, так как он не связан напрямую с данными программы, и эти области памяти не управляются сборщиком мусора.</p>

<hr class="border-2">

<p id="chapter2-1-1" class="h4 p-2">Память</p>

<p class="justify-style">В настоящее время существует два основных типа памяти, используемых в персональных компьютерах, которые значительно различаются как по стоимости производства и использования, так и по производительности:</p>

<ul class="bullet-list ms-1">
  <li>
    <p class="justify-style"><span class="fw-bold fst-italic">Статическая оперативная память</span> (SRAM): Обеспечивает очень быстрый доступ, но является довольно сложной, состоящей из 4–6 транзисторов на ячейку (хранящую один бит). Она сохраняет данные, пока питание включено, и не требует обновления. Из-за высокой скорости используется в основном в кэшах процессора.</p>
    </li>
    <li>
    <p class="justify-style"><span class="fw-bold fst-italic">Динамическая оперативная память</span> (DRAM): Очень простая конструкция ячейки (гораздо меньше, чем у SRAM) состоит из одного транзистора и конденсатора. Из-за утечки заряда конденсатора ячейка требует постоянного обновления (что занимает драгоценные миллисекунды и замедляет чтение памяти). Сигнал, считанный с конденсатора, должен быть усилен, что усложняет процесс. Чтение и запись также занимают время и не являются линейными из-за задержек конденсатора (требуется некоторое время для получения правильного чтения или успешной записи).</p>
    </li>
</ul>

<p class="justify-style">Давайте уделим еще несколько слов технологии DRAM, так как она является основой широко используемой памяти, установленной в слотах DIMM наших компьютеров. Как уже упоминалось, одна ячейка DRAM состоит из транзистора и конденсатора и хранит один бит данных. Такие ячейки сгруппированы в массивы DRAM. Адрес для доступа к конкретной ячейке предоставляется через так называемые адресные линии.</p>

<p class="justify-style">Было бы очень сложно и дорого, если бы каждая ячейка в массиве DRAM имела свой собственный адрес. Например, в случае 32-битной адресации потребовался бы 32-битный декодер адресных линий (компонент, отвечающий за выбор конкретной ячейки). Количество адресных линий в значительной степени влияет на общую стоимость системы – чем больше линий, тем больше выводов и соединений между контроллером памяти и чипами памяти (модулями). Из-за этого адресные линии используются повторно как строки и столбцы (см. <a href="#f-2-6">Рисунок 2-6</a>), и для предоставления полного адреса требуется дважды записывать на одни и те же линии.</p>

<figure id="f-2-6" class="figure">
  <img src="content/img/2-6.png" class="img-fluid" alt="Рисунок 2-6" max-width="600">
  <figcaption class="figure-caption">Рисунок 2-6. Пример чипа DRAM с массивом DRAM и наиболее важными каналами: адресные линии, 
    RAS и CAS</figcaption>
</figure>

<p class="justify-style">Чтение одного бита из конкретной ячейки занимает несколько шагов:</p>

<ol class="number-list ms-1">
  <li>
    <p class="justify-style">Номер строки помещается на адресные линии.</p>
    </li>
    <li>
    <p class="justify-style">Интерпретация запускается сигналом стробирования адреса строки (RAS) на выделенной линии.</p>
    </li>
    <li>
    <p class="justify-style">Номер столбца помещается на адресные линии.</p>
    </li>
    <li>
      <p class="justify-style">Интерпретация запускается сигналом стробирования адреса столбца (CAS).</p>
    </li>
    <li>
      <p class="justify-style">Строка и столбец указывают на конкретную ячейку DRAM в массиве. Один бит считывается из ячейки и записывается на линию данных.</p>
    </li>
</ol>

<p class="justify-style">Модули DRAM, установленные в наших компьютерах, состоят из множества таких массивов DRAM, организованных таким образом, чтобы мы могли получить доступ к нескольким битам (одному слову) за один тактовый цикл.</p>

<p class="justify-style">Временные интервалы перехода между отдельными шагами получения этого одного бита сильно влияют на производительность памяти. Эти временные интервалы могут быть вам знакомы, так как они являются важным фактором в спецификации модулей памяти, что сильно влияет на их цену. Вы, вероятно, знаете о таймингах модулей DIMM, таких как DDR3 9-9-9-24. Все эти тайминги указывают количество тактовых циклов, необходимых для выполнения определенных действий. Соответственно, они имеют следующие значения:</p>

<ul class="bullet-list ms-1">
  <li>
    <p class="justify-style">tCL (CAS латентность): Время между стробом адреса столбца (CAS) и началом ответа (получением данных).</p>
    </li>
    <li>
    <p class="justify-style">tRCD (задержка RAS до CAS): Минимальное время между стробом адреса строки (RAS) и стробом адреса столбца (CAS).</p>
    </li>
    <li>
    <p class="justify-style">tRP (предзарядка строки): Время, необходимое для предзарядки строки перед доступом к ней. Строка не может быть использована без предварительной подготовки, называемой предзарядкой.</p>
    </li>
    <li>
    <p class="justify-style">tRAS (задержка активной строки): Минимальное время, в течение которого строка должна быть активной для доступа к информации в ней.</p>
    </li>
</ul>

<p class="justify-style">Обратите внимание на важность этих временных интервалов. Если строка и столбец, которые вас интересуют, уже установлены, считывание происходит почти мгновенно. Если вы хотите изменить столбец, это займет tCL тактовых циклов. Если вы хотите изменить строку, ситуация намного хуже: сначала она должна быть перезаряжена (tRP циклы), затем следуют задержки RAS и CAS (tCL и tRCD).</p>

<p class="justify-style">Все эти временные интервалы важны для пользователей компьютеров, ожидающих максимальной производительности. Игроки особенно обращают внимание на эти параметры. При покупке модулей памяти вы должны стремиться к минимально возможным таймингам, которые вы можете себе позволить, если производительность является вашим приоритетом.</p>

<p class="justify-style">Однако нас интересует влияние архитектуры памяти DRAM и ее таймингов на управление памятью. Стоимость изменения строки – временные интервалы сигнала RAS и перезарядка – значительна. Это одна из многих причин, почему последовательные шаблоны доступа к памяти намного быстрее, чем непоследовательные. Чтение данных в режиме burst из одной строки (изменяя столбец время от времени) намного быстрее, чем частое изменение строки. Если шаблон доступа полностью случайный, вы, скорее всего, столкнетесь с этими временными интервалами изменения строки при каждом доступе к памяти.</p>

<p class="justify-style">Вся представленная здесь информация имеет одну цель – убедиться, что у вас есть глубокая причина запомнить, почему непоследовательный доступ к памяти так нежелателен. И, как вы увидите, это не единственная причина, почему полностью случайный доступ является наихудшим сценарием.</p>

<hr class="border-2">

<p id="chapter2-1-2" class="h4 p-2">ЦПУ</p>

<p class="justify-style">Теперь перейдем к теме центрального процессора. Процессор совместим с так называемой архитектурой набора инструкций (ISA) – она определяет, среди прочего, набор операций, которые могут выполняться (инструкции), регистры и их значение, как адресуется память и так далее. В этом смысле ISA является контрактом (интерфейсом), установленным между производителем процессора и его пользователями – программами, написанными в соответствии с данным контрактом. Это уровень, который вы видите при программировании, например, на языке ассемблера данной архитектуры. ISA IA-32 (32-битные процессоры i386, Pentium 32-битные процессоры), совместимые с AMD64 (большинство современных процессоров, включая Intel Core, AMD FX и Zen и т.д.), и A64 для ARM64 являются наиболее широко используемыми в мире экосистемы .NET. Под ISA находится так называемая микроархитектура процессора, которая ее реализует. Это позволяет улучшать микроархитектуру без влияния на систему и программное обеспечение, сохраняя обратную совместимость.</p>

<br>
<div class="card text-bg-info mb-3 bg-opacity-10">
  <div class="card-header"><i class="bi bi-info-square"></i> Примечание</div>
  <div class="card-body">
    <p class="card-text justify-style">Существует много путаницы с названиями стандартов 64-битной архитектуры, и вы часто можете встретить x86-64, EMT64T, Intel 64 или AMD64, используемые взаимозаменяемо. Несмотря на наличие имен производителей и иногда незначительные различия, для целей этой книги вы можете смело считать, что эти названия однозначны и могут быть безопасно заменены друг на друга.</p>
  </div>
</div>

<p class="justify-style">Как было сказано в предыдущей главе, регистры являются ключевыми компонентами ЦПУ, потому что в настоящее время все компьютеры реализованы как регистровые машины. В контексте манипуляции данными доступ к регистрам является мгновенным в том смысле, что он происходит в течение одного процессорного цикла и не вызывает дополнительных задержек. Нет места для ваших данных ближе к ЦПУ, чем регистры процессора. Конечно, регистры хранят только данные, необходимые для текущих инструкций, поэтому их нельзя считать универсальной памятью. На самом деле, в общем, процессоры имеют больше регистров, чем это видно из их ISA. Это позволяет выполнять различные типы оптимизаций (например, так называемое переименование регистров). Однако это детали реализации микроархитектуры и не влияют на механизмы управления памятью.</p>

<p class="h5 p-2">Кэш ЦПУ</p>

<p class="justify-style">Как мы уже упоминали ранее, чтобы уменьшить разрыв в производительности между ЦПУ и ОЗУ, используется 
  промежуточный компонент для хранения копий наиболее часто используемых и необходимых данных – кэш ЦПУ. В общем виде это 
  показано на <a href="#2-7">Рисунке 2-7</a>.</p>

<figure id="f-2-7" class="figure">
  <img src="content/img/2-7.png" class="img-fluid" alt="Рисунок 2-7" max-width="600">
  <figcaption class="figure-caption">Рисунок 2-7. Взаимосвязь ЦПУ с кэшем и ОЗУ</figcaption>
</figure>

<p class="justify-style">Этот кэш прозрачен с точки зрения ISA. Ни программисту, ни операционной системе не нужно знать о ее существовании. Они не обязаны им управлять. В идеальном мире правильное использование и управление кэшем должно быть исключительной ответственностью центрального процессора.</p>

<p class="justify-style">Поскольку кэш должен быть максимально быстрым, используются ранее упомянутые чипы SRAM. Из-за своей стоимости и размера (занимающего драгоценное место в процессоре) они не могут иметь такую ​​же большую емкость, как основная оперативная память. Но в зависимости от предполагаемых затрат они могут быть такими же быстрыми, как ЦП, или может быть, только на один-два порядка медленнее.</p>

<p class="h5 p-2">Попадание и промах кэша</p>

<p class="justify-style">Идея кэша тривиальна. Когда выполняемая процессором инструкция нуждается в доступе к памяти (будь то запись или чтение), она сначала проверяет кэш, чтобы узнать, находятся ли нужные данные уже там. Если да, то отлично! Вы только что получили очень быстрый доступ к памяти, и такая ситуация называется попаданием в кэш. Если данных нет в кэше (так называемый промах кэша), то сначала их нужно прочитать из ОЗУ перед тем, как сохранить в кэш, что, очевидно, является гораздо более медленной операцией. Соотношение попаданий и промахов кэша являются очень важными показателями, показывающими, насколько эффективно наш код использует кэш.</p>

<p class="h5 p-2">Локальность данных</p>

<p class="justify-style"> Но почему такой кэш вообще полезен? Кэширование основано на очень важной концепции – <span class="fw-bold fst-italic">локальности данных</span>. Вы можете различить два вида локальности:</p>

<ul class="bullet-list ms-1">
  <li>
    <p class="justify-style"><span class="fw-bold fst-italic">Временная локальность</span>: Если вы обращаетесь к какому-то региону памяти, вы, скорее всего, обратитесь к нему снова в ближайшем будущем. Это делает использование кэша вполне оправданным – вы читаете некоторые данные из памяти и, вероятно, будете использовать их позже еще несколько раз. В общем, вы загружаете некоторые структуры данных в переменные и используете эти переменные многократно (счетчики, временные данные, считанные из файлов и так далее).</p>
    </li>
    <li>
    <p class="justify-style"><span class="fw-bold fst-italic">Пространственная локальность</span>: Если вы обращаетесь к какому-то региону памяти, вы, скорее всего, обратитесь к данным из близкого окружения. Этот тип локальности может стать вашим союзником, если вы кэшируете немного больше окружающих данных, чем вам нужно в данный момент. Например, если вам нужно несколько байт из памяти, давайте прочитаем и за кэшируем еще десяток байт. Вы редко используете очень изолированные области памяти. Вы скоро обнаружите, что стек и куча организованы таким образом, что потоки, выполняющие свою работу, обычно обращаются к похожим областям памяти. Локальные переменные или поля в структурах данных также обычно размещаются близко друг к другу.</p>
    </li>
</ul>

<p class="justify-style">Обратите внимание, что кэш полезен, если вышеупомянутые условия действительно выполняются. Однако это палка о двух концах. Если вы напишете программу таким образом, что она нарушает локальность данных, кэш станет ненужной обузой. Вы увидите это позже в главе.</p>

<p class="h5 p-2">Реализация кэша</p>

<p class="justify-style">До тех пор, пока сохраняется совместимость с моделью памяти ISA, детали реализации кэша теоретически не имеют значения. Он должен быть просто для ускорения доступа к памяти и все. Тем не менее, это прекрасный пример <span class="fw-bold fst-italic">Закона дырявых абстракций</span>, придуманного Джоэлом Спольски:</p>

<br>
<div class="card text-bg-info mb-3 bg-opacity-10">
  <div class="card-header"><i class="bi bi-info-square"></i> Цитата</div>
  <div class="card-body">
    <p class="card-text justify-style">Все нетривиальные абстракции, в той или иной степени, дырявые</p>
  </div>
</div>

<p class="justify-style">Это означает, что абстракция, которая теоретически должна скрывать детали реализации, к сожалению, при определенных обстоятельствах раскрывает их наружу. И обычно это происходит непредсказуемым и/или нежелательным образом. Как это работает в случае с кэшем, должно стать ясно в ближайшее время, а пока давайте просто немного углубимся в детали реализации.</p>

<p class="justify-style">Самым важным и влиятельным фактом является то, что данные между оперативной памятью и кэшем передаются блоками, называемыми строкой кэша. Строка кэша имеет фиксированный размер, и в подавляющем большинстве современных компьютеров он составляет 64 байта. Очень важно помнить – вы не можете прочитать или записать меньше данных из памяти, чем размер строки кэша, то есть 64 байта. Даже если вы захотите прочитать один бит из памяти, будет заполнена целая 64-байтовая строка кэша. В этой конструкции используется более быстрый последовательный доступ к DRAM (помните задержки предварительной зарядки и RAS, описанные ранее в этой главе?).</p>

<p class="justify-style">Как уже упоминалось ранее, доступ к DRAM осуществляется с шириной 64 бита (8 байт), поэтому для заполнения такой строки кэша требуется восемь передач из ОЗУ. Это требует многих циклов ЦПУ, поэтому существуют различные техники для оптимизации этого процесса. Одна из них называется "Critical Word First" и "Early Restart". Она позволяет не читать строку кэша слово за словом, а начинать с самого нужного слова. Представьте, что в худшем случае такое 8-байтовое слово может находиться в конце строки кэша, и вам пришлось бы ждать все предыдущие семь передач, чтобы получить доступ к нему. Эта техника сначала читает самое важное слово. Инструкции, ожидающие эти данные, могут продолжить выполнение, а остальная часть строки кэша будет заполнена асинхронно.</p>

<br>
<div class="card text-bg-info mb-3 bg-opacity-10">
  <div class="card-header"><i class="bi bi-info-square"></i> Примечание</div>
  <div class="card-body">
    <p class="card-text justify-style">Как выглядит типичный шаблон доступа к памяти? Когда кто-то хочет прочитать данные из памяти, соответствующая строка кэша создается в кэше, и в нее считываются 64 байта данных. Когда кто-то хочет записать данные в память, первый шаг точно такой же – строка кэша заполняется в кэше, если ее там еще нет. Эти кэшированные данные изменяются при записи данных. Затем могут произойти две стратегии:</p>
    <ul class="bullet-list ms-1">
      <li>
      <p class="justify-style"><span class="fw-bold fst-italic">Запись через</span>: После записи в строку кэша измененные данные немедленно сохраняются в основной памяти. Это простой подход для реализации, но создает большую нагрузку на шину памяти.</p>
      </li>
      <li>
      <p class="justify-style"><span class="fw-bold fst-italic">Запись обратно</span>: После записи в строку кэша она помечается как грязная. Затем, когда в кэше нет места для других данных, этот грязный блок записывается в память (и измененная грязная запись кэша удаляется). Процессор может записывать эти блоки время от времени, когда сочтет это уместным (например, во время простоя).</p>
      </li>
    </ul>
    <p class="card-text justify-style">Существует еще одна техника оптимизации, называемая объединением записей. Она гарантирует, что данная строка кэша из данной области памяти записывается полностью (а не записываются отдельные слова), снова используя преимущество более быстрого последовательного доступа к памяти.</p>
  </div>
</div>

<p class="justify-style">Из-за строк кэша, данные хранящиеся в памяти, выравниваются по границе в 64 байта. Таким образом, чтобы прочитать два последовательных байта, в худшем случае необходимо использовать две строки кэша общим размером 128 байт. Это показано на <a href="#f-2-8">Рисунке 2-8</a>, когда вы хотите прочитать 2 байта по адресу A, но он находится всего в одном байте до конца границы строки кэша, в таком случае вам в итоге придётся читать две строки кэша.</p>

<figure id="f-2-8" class="figure">
  <img src="content/img/2-8.png" class="img-fluid" alt="Рисунок 2-8" max-width="600">
  <figcaption class="figure-caption">Рисунок 2-8. Доступ к двум последовательным байтам требует заполнения двух строк кэша, поскольку они, к сожалению, были расположены на границе двух сток кеша.</figcaption>
</figure>

<p class="justify-style">Текст...</p>

<p class="justify-style">Текст...</p>

<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-2" class="h3 p-2">Операционная система</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-2-1" class="h4 p-2">Виртуальная память</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-2-2" class="h4 p-2">Большие страницы</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-2-3" class="h4 p-2">Фрагментация виртуальной памяти</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-2-4" class="h4 p-2">Общая компоновка памяти</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-2-5" class="h4 p-2">Управление памятью в Windows</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-2-6" class="h4 p-2">Компоновка памяти в Windows</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-2-7" class="h4 p-2">Управление памятью в Linux</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-2-8" class="h4 p-2">Компоновка памяти в Linux</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-2-9" class="h4 p-2">Влияние операционной системы</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-3" class="h3 p-2">NUMA и группы ЦПУ</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-4" class="h3 p-2">Резюме</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-4-1" class="h4 p-2">Правило 2 - Следует избегать случайного доступа, поощрять последовательный доступ</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-4-2" class="h4 p-2">Правило 3 - Улучшайте пространственную и временную локальность данных</p>
<p class="justify-style">Текст...</p>

<hr class="border-2">
<p id="chapter2-4-3" class="h4 p-2">Правило 4 - Рассмотрите более продвинутые возможности</p>
<p class="justify-style">Текст...</p>


<!--
Глава 2: Низкоуровневое управление памятью
  Аппаратное обеспечение
    Память
    ЦПУ
  Операционная система
    Виртуальная память
    Большие страницы
    Фрагментация виртуальной памяти
    Общая компоновка памяти
    Управление памятью в Windows
    Компоновка памяти в Windows
    Управление памятью в Linux
    Компоновка памяти в Linux
    Влияние операционной системы
  NUMA и группы ЦПУ
  Резюме
    Правило 2 - Следует избегать случайного доступа, поощрять последовательный доступ
    Правило 3 - Улучшайте пространственную и временную локальность данных
    Правило 4 - Рассмотрите более продвинутые возможности
-->
    
    